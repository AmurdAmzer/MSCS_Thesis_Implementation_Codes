{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmurdAmzer/SAKT-Paper_Implementation/blob/main/SAKTPaperImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Mjf06XlwkI"
      },
      "source": [
        "# Cell 1: Uploading data via Colab's File Browser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LacccNggl2gy",
        "outputId": "3621b410-25b0-47b3-a7ec-e4fcef4579aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in current directory:\n",
            " - skill_builder_data_corrected_collapsed.csv\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Uploading data via Colab's File Browser\n",
        "\n",
        "# os stands for \"Operating System\" - it's like a special toolkit that lets your Python code talk to your computer's file system.\n",
        "import os\n",
        "print(\"Files in current directory:\")\n",
        "for file in os.listdir():\n",
        "  if file.endswith(\".csv\"):\n",
        "    print(f\" - {file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soB_jKNd5A3M"
      },
      "source": [
        "#Cell 2: Imports and File upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "l7PycBC01iR8",
        "outputId": "d85344d9-0868-4443-f1c3-510d005b4a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (346860, 31)\n",
            "\n",
            "Column names: ['Unnamed: 0', 'order_id', 'assignment_id', 'user_id', 'assistment_id', 'problem_id', 'original', 'correct', 'attempt_count', 'ms_first_response', 'tutor_mode', 'answer_type', 'sequence_id', 'student_class_id', 'position', 'type', 'base_sequence_id', 'skill_id', 'skill_name', 'teacher_id', 'school_id', 'hint_count', 'hint_total', 'overlap_time', 'template_id', 'answer_id', 'answer_text', 'first_action', 'bottom_hint', 'opportunity', 'opportunity_original']\n",
            "\n",
            "First 5 rows:    Unnamed: 0  order_id  assignment_id  user_id  assistment_id  problem_id  \\\n",
            "0           1  33022537         277618    64525          33139       51424   \n",
            "1           2  33022709         277618    64525          33150       51435   \n",
            "2           3  35450204         220674    70363          33159       51444   \n",
            "3           4  35450295         220674    70363          33110       51395   \n",
            "4           5  35450311         220674    70363          33196       51481   \n",
            "\n",
            "   original  correct  attempt_count  ms_first_response  ... hint_count  \\\n",
            "0         1        1              1              32454  ...          0   \n",
            "1         1        1              1               4922  ...          0   \n",
            "2         1        0              2              25390  ...          0   \n",
            "3         1        1              1               4859  ...          0   \n",
            "4         1        0             14              19813  ...          3   \n",
            "\n",
            "  hint_total  overlap_time  template_id  answer_id answer_text  first_action  \\\n",
            "0          3         32454        30799        NaN          26             0   \n",
            "1          3          4922        30799        NaN          55             0   \n",
            "2          3         42000        30799        NaN          88             0   \n",
            "3          3          4859        30059        NaN          41             0   \n",
            "4          4        124564        30060        NaN          65             0   \n",
            "\n",
            "  bottom_hint opportunity  opportunity_original  \n",
            "0         NaN           1                   1.0  \n",
            "1         NaN           2                   2.0  \n",
            "2         NaN           1                   1.0  \n",
            "3         NaN           2                   2.0  \n",
            "4         0.0           3                   3.0  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Imports and File upload (df = pd.read_csv(....)) opens the spreadsheet(data) and puts it into a \"DataFrame\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the CSV file (Remember to use the actual file name)\n",
        "# encoding='ISO-8859-1' handles special characters in the data\n",
        "# low_memory=False prevents dtype warnings for mixed types\n",
        "\n",
        "# I choose to call my loaded data df, df can mean DataFrame, df is just a variable name, I can choose to name my uploaded data anything.\n",
        "# low_memory=False tells the computer \"take your time reading this properly, don't rush\"\n",
        "# encoding='ISO-8859-1' = Like telling your computer \"hey, this file might have special characters like currency symbols ($ etc.)\".\n",
        "#  Real-Life Analogy\n",
        "\"\"\"\n",
        "It's like telling your computer:\n",
        "When you read this file, treat these bytes or symbols as Latin-style letters â€” not random gibberish.\"\n",
        "\n",
        "If you don't specify the correct encoding, Python might fail to read the file\n",
        "\"\"\"\n",
        "\n",
        "df = pd.read_csv('skill_builder_data_corrected_collapsed.csv', encoding='ISO-8859-1', low_memory=False)\n",
        "\n",
        "# Show basic information about the dataset\n",
        "print(f\"Dataset shape: {df.shape}\") # (rows, columns)\n",
        "print(f\"\\nColumn names: {list(df.columns)}\") # all column names\n",
        "print(f\"\\nFirst 5 rows: {df.head()}\") # preview first 5 rows. head() has a default parameter built in df.head(n=5). you could specify by df.head(5) etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1.5: Random Seed Function (Add after imports)\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seeds(seed=42):\n",
        "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    print(f\"Random seeds set to {seed}\")"
      ],
      "metadata": {
        "id": "8SyfRVMif8zD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir9cX3Pr5Ncc"
      },
      "source": [
        "# Cell3: Key Statistics - Understanding the dataset size and scope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cqUdL-mz24hc",
        "outputId": "e61484b9-9fec-43a4-eda2-947b848eb9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===DATASET OVERVIEW===\n",
            "Toatal interactions: 346860\n",
            "Unique students: 4217\n",
            "Unique problems: 26688\n",
            "Unique skills: 149\n",
            "\n",
            "Correct rate: 64.53%\n",
            "Rows with skill_id: 283105\n",
            "Rows missing skill_id: 63755 (18.4%)\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Key Statistics - Understanding the dataset size and scope\n",
        "\n",
        "print(\"===DATASET OVERVIEW===\")\n",
        "\n",
        "# Count total number of student interactions = number of rows\n",
        "print(f\"Toatal interactions: {len(df)}\")\n",
        "\n",
        "# Count unique students - each student has a unique user_id\n",
        "print(f\"Unique students: {df['user_id'].nunique()}\") # df['user_id] = access the user id column. nunique = count how many unique values are in that column\n",
        "\n",
        "# Count unique problems - individual questions students attempted\n",
        "print(f\"Unique problems: {df['problem_id'].nunique()}\")\n",
        "\n",
        "# Count unique skills - knowledge concepts being tested. this is crucial because I will create embeddings for each skill\n",
        "print(f\"Unique skills: {df['skill_id'].nunique()}\")\n",
        "\n",
        "# Calculate overall performance - percentage of correct answers\n",
        "print(f\"\\nCorrect rate: {df['correct'].mean():.2%}\")  # .2% means format the number as percentage with two decimal places, so for eg. 0.825641 becomes 82.56%\n",
        "\n",
        "# Check data completeness for skill_id (Critical for SAKT)\n",
        "# NB. SAKT needs skill_id to work - rows without the skill_id must be removed\n",
        "print(f\"Rows with skill_id: {df['skill_id'].notna().sum()}\")\n",
        "print(f\"Rows missing skill_id: {df['skill_id'].isna().sum()} ({df['skill_id'].isna().mean():.1%})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhKU22wsrOMe"
      },
      "source": [
        "# CELL 4: Examine One Student's Learning Journey (Creating a case study).\n",
        "# Before SAKT learns from all students, you want to see what one student's learning path looks like\n",
        "# This helps to understand the sequential nature of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8nUiiGtprW7R",
        "outputId": "8c53b86d-f8fb-4b21-daed-ee42d083b730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student 96235 attempted 977 problems\n",
            "Skills attempted: 87\n",
            "Correct rate: 58.03%\n",
            "\n",
            "First 30 attempts:\n",
            "        order_id skill_id  correct  ms_first_response\n",
            "96959   38171250       49        0               6228\n",
            "96960   38171251       49        1               4544\n",
            "96961   38171252       49        1               6059\n",
            "96962   38171253       49        0               6154\n",
            "96963   38171254       49        0              11896\n",
            "96964   38171255       49        1              11180\n",
            "96965   38171256       49        0               5603\n",
            "96966   38171257       49        0               5152\n",
            "96967   38171258       49        0               8184\n",
            "96968   38171259       49        0               3551\n",
            "96969   38171260       49        1               7122\n",
            "96970   38171261       49        1               4576\n",
            "96971   38171262       49        0               4139\n",
            "96972   38171263       49        0               6022\n",
            "96973   38171264       49        0              14956\n",
            "96974   38171265       49        1               9418\n",
            "96975   38171266       49        1              11435\n",
            "96976   38171267       49        0               6624\n",
            "96977   38171268       49        0               6217\n",
            "96978   38171269       49        1               9203\n",
            "259830  38171273      311        1             105282\n",
            "229704  38171275      307        1              15819\n",
            "259831  38171300      311        1              80594\n",
            "282263  38171301      368        0              64103\n",
            "282264  38171302      368        0             113526\n",
            "282265  38171303      368        1              67698\n",
            "282266  38171304      368        1              48215\n",
            "282267  38171305      368        1              92317\n",
            "60818   38171315       32        1              12908\n",
            "11447   38171316        4        0              15694\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Examine One Student's (random) Learning Journey\n",
        "# This helps us understand the sequential nature of the data\n",
        "\n",
        "# Find students sorted by number of attempts (most active students)\n",
        "student_activity = df['user_id'].value_counts()\n",
        "\n",
        "# Pick the 11th most active student (avoid outliers)\n",
        "student_id = student_activity.index[20]\n",
        "\n",
        "# Get all data for this student, sorted by time\n",
        "# Order_id represents the sequence of attempsts\n",
        "\n",
        "student_data = df[df['user_id'] == student_id].sort_values('order_id')\n",
        "\n",
        "# Display student summary\n",
        "print(f\"Student {student_id} attempted {len(student_data)} problems\")\n",
        "print(f\"Skills attempted: {student_data['skill_id'].nunique()}\")\n",
        "print(f\"Correct rate: {student_data['correct'].mean():.2%}\")\n",
        "\n",
        "# Show their first 30 attempts to see the sequential Pattern\n",
        "print(\"\\nFirst 30 attempts:\")\n",
        "print(student_data[['order_id', 'skill_id', 'correct', 'ms_first_response']].head(30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4AOb7nX5wK_"
      },
      "source": [
        "# CELL 5: Visualize Key Patterns to Understand The Data Better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1454
        },
        "id": "WPbKjUOS5vWK",
        "outputId": "2e0b49a5-8aee-49d4-b1e7-5441363fed44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top 20 Most Active Students:\n",
            "user_id: sequence length\n",
            "78978:     1383\n",
            "78970:     1334\n",
            "79032:     1264\n",
            "79021:     1239\n",
            "96274:     1236\n",
            "78979:     1163\n",
            "96244:     1149\n",
            "75169:     1129\n",
            "79013:     1124\n",
            "78989:     1115\n",
            "79029:     1112\n",
            "78980:     1112\n",
            "79019:     1095\n",
            "71881:     1089\n",
            "78987:     1084\n",
            "96243:     1083\n",
            "79031:     1064\n",
            "79018:     1041\n",
            "96265:     1014\n",
            "79012:     1005\n",
            "\n",
            "\n",
            "Buttom 20 Least Active Students:\n",
            "user_id: sequence length\n",
            "87376:     1\n",
            "82017:     1\n",
            "86706:     1\n",
            "88329:     1\n",
            "88340:     1\n",
            "88358:     1\n",
            "92380:     1\n",
            "92527:     1\n",
            "77725:     1\n",
            "87434:     1\n",
            "78101:     1\n",
            "78252:     1\n",
            "78241:     1\n",
            "87448:     1\n",
            "71163:     1\n",
            "71560:     1\n",
            "71573:     1\n",
            "76986:     1\n",
            "74864:     1\n",
            "51933:     1\n",
            "\n",
            "\n",
            "20 Random students sorted by length\n",
            "user_id: sequence length\n",
            "86293:     1\n",
            "91245:     2\n",
            "87423:     2\n",
            "87114:     2\n",
            "87594:     5\n",
            "87466:     5\n",
            "91246:     7\n",
            "80093:     15\n",
            "81481:     15\n",
            "90010:     19\n",
            "91040:     20\n",
            "78999:     23\n",
            "84742:     24\n",
            "86415:     53\n",
            "79545:     74\n",
            "84333:     74\n",
            "72059:     109\n",
            "79491:     131\n",
            "79218:     172\n",
            "79583:     299\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Distribution of Student Sequence Lengths')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# CELL 5: Visualing Key Patterns to Understand the Data Better\n",
        "\n",
        "# Calculate seuence length for each student (how many problems/quenstions/skills did each student attempt)\n",
        "\n",
        "seq_lengths = df.groupby('user_id').size()\n",
        "\n",
        "# seq_len for the Top 20 students\n",
        "print(\"top 20 Most Active Students:\")\n",
        "print(\"user_id: sequence length\")\n",
        "sorted_seq = seq_lengths.sort_values(ascending=False)\n",
        "for user_id, length in sorted_seq.head(20).items():\n",
        "  print(f\"{user_id}:     {length}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# seq_len for the Buttom 20 students\n",
        "print(\"Buttom 20 Least Active Students:\")\n",
        "print(\"user_id: sequence length\")\n",
        "sorted_seq = seq_lengths.sort_values(ascending=False)\n",
        "for user_id, length in sorted_seq.tail(20).items():\n",
        "  print(f\"{user_id}:     {length}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Random 20 students sorted by length\n",
        "print(\"20 Random students sorted by length\")\n",
        "print(\"user_id: sequence length\")\n",
        "random_sample = seq_lengths.sample(20).sort_values() # If you remove the ascending argument, pandas uses the default, which is: ascending=True\n",
        "for user_id, length in random_sample.items():\n",
        "  print(f\"{user_id}:     {length}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(30,10))\n",
        "\n",
        "# Subplot 1. Distribution of Student Sequence Lengths. This shows us whether we have enough data per student for SAKT\n",
        "#plt.subplot(1,2,1)\n",
        "plt.hist(seq_lengths, bins=150, edgecolor='black')\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Number of Students')\n",
        "plt.title('Distribution of Student Sequence Lengths')\n",
        "\n",
        "#Subplot 2. Most Attempted Skills. This shows if some skills dominate the dataset.\n",
        "#plt.subplot(1,2,2)\n",
        "\n",
        "# Count attempts per skill and get top 20.\n",
        "#skill_attempts = df.groupby('skill_id').size().sort_values(ascending=False)\n",
        "#top_skills = skill_attempts.head(20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATuGUM4053dg"
      },
      "source": [
        "# CELL 6: Data Quality Check - Critical for Reliable Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Nh6WRXAH56qi",
        "outputId": "cba5d746-97c4-45cc-ba6f-57710c4b4da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Quality Report:\n",
            "----------------------------------------\n",
            "Duplicate rows: 0\n",
            "Students with <5 attempts: 473 (11.2%)\n",
            "Students with >500 attempts: 181\n",
            "All sequences properly ordered: True\n",
            "\n",
            "Original problems: 275458 (79.4%)\n",
            "Scaffolding problems: 71402 (20.6%)\n",
            "SAKT paper uses only original problems\n",
            "\n",
            "Answer distribution:\n",
            "Correct: 223818 (64.5%)\n",
            "Incorrect: 123042 (35.5%)\n",
            "\n",
            "Missing data analysis:\n",
            "Missing skill_id: 63755 rows (18.4%)\n",
            "Missing user_id: 0 rows\n",
            "Missing correct: 0 rows\n",
            "SAKT requires skill_id, user_id, and correct to be present\n"
          ]
        }
      ],
      "source": [
        "# CELL 6: Data Quality Check - Critical for Reliable Model Training\n",
        "\n",
        "print(\"Data Quality Report:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Check 1: Duplicate rows (same data appearing multiple times)\n",
        "duplicate_count = df.duplicated().sum()\n",
        "print(f\"Duplicate rows: {duplicate_count}\")\n",
        "if duplicate_count > 0:\n",
        "    print(\"Need to remove duplicates!\")\n",
        "\n",
        "# Check 2: Students with very few attempts\n",
        "# SAKT needs sufficient history to learn patterns\n",
        "too_few = (seq_lengths < 5).sum()\n",
        "print(f\"Students with <5 attempts: {too_few} ({too_few/len(seq_lengths)*100:.1f}%)\")\n",
        "\n",
        "# Check 3: Students with too many attempts (potential outliers)\n",
        "too_many = (seq_lengths > 500).sum()\n",
        "print(f\"Students with >500 attempts: {too_many}\")\n",
        "\n",
        "# Check 4: Temporal ordering validation\n",
        "# Sort by user and order_id to check sequence integrity\n",
        "df_sorted = df.sort_values(['user_id', 'order_id'])\n",
        "# For each user, check if order_id always increases\n",
        "is_ordered = df_sorted.groupby('user_id')['order_id'].apply(\n",
        "    lambda x: (x.diff().dropna() > 0).all()  # diff() calculates difference between consecutive values\n",
        ").all()\n",
        "print(f\"All sequences properly ordered: {is_ordered}\")\n",
        "\n",
        "# Check 5: Original vs scaffolding problems\n",
        "# Original = main problem, scaffolding = hints/sub-problems\n",
        "original_count = (df['original'] == 1).sum()\n",
        "scaffold_count = (df['original'] == 0).sum()\n",
        "print(f\"\\nOriginal problems: {original_count} ({original_count/len(df)*100:.1f}%)\")\n",
        "print(f\"Scaffolding problems: {scaffold_count} ({scaffold_count/len(df)*100:.1f}%)\")\n",
        "print(\"SAKT paper uses only original problems\")\n",
        "\n",
        "# Check 6: Answer distribution\n",
        "print(f\"\\nAnswer distribution:\")\n",
        "print(f\"Correct: {(df['correct'] == 1).sum()} ({df['correct'].mean()*100:.1f}%)\")\n",
        "print(f\"Incorrect: {(df['correct'] == 0).sum()} ({(1-df['correct'].mean())*100:.1f}%)\")\n",
        "\n",
        "# Check 7: Critical missing data for SAKT\n",
        "print(f\"\\nMissing data analysis:\")\n",
        "print(f\"Missing skill_id: {df['skill_id'].isna().sum()} rows ({df['skill_id'].isna().mean()*100:.1f}%)\")\n",
        "print(f\"Missing user_id: {df['user_id'].isna().sum()} rows\")\n",
        "print(f\"Missing correct: {df['correct'].isna().sum()} rows\")\n",
        "print(\"SAKT requires skill_id, user_id, and correct to be present\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKW2EPOJ7Y3Y"
      },
      "source": [
        "# CELL 7: Data Preprocessing for SAKT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: Data Preprocessing (Original Problems Only - Following SAKT Paper)\n",
        "\n",
        "print(\"Starting data preprocessing...\")\n",
        "print(f\"Original data shape: {df.shape}\")\n",
        "\n",
        "# Step 1: Keep only original problems (main problems, not hints)\n",
        "# SAKT paper specifies using only original problems\n",
        "df_clean = df[df['original'] == 1].copy()\n",
        "print(f\"After keeping only original problems: {df_clean.shape}\")\n",
        "\n",
        "# Step 2: Remove rows with missing skill_id\n",
        "# SAKT requires skill_id to create embeddings\n",
        "df_clean = df_clean.dropna(subset=['skill_id'])\n",
        "df_clean['skill_id'] = df_clean['skill_id'].astype(int)\n",
        "print(f\"After removing missing skill_id: {df_clean.shape}\")\n",
        "\n",
        "# Step 3: Convert skill_id to integer (it might be float due to NaN values)\n",
        "df_clean['skill_id'] = df_clean['skill_id'].astype(int)\n",
        "\n",
        "# Step 4: Minimum sequence length of 5. Keep only students with >= 0 attempts\n",
        "# Too few attempts don't provide enough learning history\n",
        "MIN_SEQUENCE_LENGTH = 5\n",
        "student_seq_lengths = df_clean.groupby('user_id').size()\n",
        "valid_students = student_seq_lengths[student_seq_lengths >= MIN_SEQUENCE_LENGTH].index\n",
        "df_clean = df_clean[df_clean['user_id'].isin(valid_students)]\n",
        "print(f\"After removing students with <{MIN_SEQUENCE_LENGTH} attempts: {df_clean.shape}\")\n",
        "\n",
        "# Step 5: Sort by user_id and order_id\n",
        "df_clean = df_clean.sort_values(['user_id', 'order_id'])\n",
        "\n",
        "print(f\"\\nFinal clean dataset:\")\n",
        "print(f\"- Total interactions: {len(df_clean)}\")\n",
        "print(f\"- Unique students: {df_clean['user_id'].nunique()}\")\n",
        "print(f\"- Unique skills: {df_clean['skill_id'].nunique()}\")\n",
        "print(f\"- Average sequence length: {df_clean.groupby('user_id').size().mean():.1f}\")\n",
        "print(f\"- Average correct rate: {df_clean['correct'].mean():.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GTIeLq3WDcCk",
        "outputId": "b666f7b2-5373-498a-f0f4-28fb40a601e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data preprocessing...\n",
            "Original data shape: (346860, 31)\n",
            "After keeping only original problems: (275458, 31)\n",
            "After removing missing skill_id: (259399, 31)\n",
            "After removing students with <5 attempts: (258153, 31)\n",
            "\n",
            "Final clean dataset:\n",
            "- Total interactions: 258153\n",
            "- Unique students: 3628\n",
            "- Unique skills: 145\n",
            "- Average sequence length: 71.2\n",
            "- Average correct rate: 65.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HVP0M2sbz818"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9i4en2K7iJ2"
      },
      "source": [
        "# CELL 8: Transform Data into SAKT Input Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "osY3ties7k2s",
        "outputId": "1e3e3033-93de-4ec7-8e69-54a1d0246672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique skills: 145\n",
            "Skill IDs range: 1 to 173190193221\n",
            "\n",
            "Creating student sequences...\n",
            "\n",
            "Example sequence (first student):\n",
            "User ID: 14\n",
            "Sequence length: 19\n",
            "First 5 skills attempted: [132, 132, 132, 132, 132]\n",
            "First 5 responses (0=wrong, 1=correct): [0 1 0 0 0]\n",
            "First 5 interaction encodings: [np.int64(132), np.int64(277), np.int64(132), np.int64(132), np.int64(132)]\n"
          ]
        }
      ],
      "source": [
        "# CELL 8: Transform Data into SAKT Input Format\n",
        "\n",
        "# Get unique skills and create mapping\n",
        "unique_skills = sorted(df_clean['skill_id'].unique())\n",
        "num_skills = len(unique_skills)\n",
        "\n",
        "# Create skill_id to index mapping (0 to num_skills-1)\n",
        "skill_to_idx = {skill: idx for idx, skill in enumerate(unique_skills)}\n",
        "\n",
        "print(f\"Number of unique skills: {num_skills}\")\n",
        "print(f\"Skill IDs range: {min(unique_skills)} to {max(unique_skills)}\")\n",
        "\n",
        "# Function to create sequences for each student\n",
        "def create_student_sequences(df_clean, skill_to_idx, num_skills):\n",
        "    \"\"\"\n",
        "    Convert student interactions into SAKT format:\n",
        "    - interaction = skill_idx + (correct * num_skills)\n",
        "    \"\"\"\n",
        "    sequences = []\n",
        "\n",
        "    # Process each student\n",
        "    for user_id, user_data in df_clean.groupby('user_id'):\n",
        "        # Get student's attempt history\n",
        "        skills = user_data['skill_id'].values\n",
        "        corrects = user_data['correct'].values\n",
        "\n",
        "        # Convert skill_id to indices\n",
        "        skill_indices = [skill_to_idx[skill] for skill in skills]\n",
        "\n",
        "        # Create interaction sequence (SAKT encoding)\n",
        "        # interaction = skill_index + (correct * num_skills)\n",
        "        interactions = []\n",
        "        for skill_idx, correct in zip(skill_indices, corrects):\n",
        "            interaction = skill_idx + (correct * num_skills)\n",
        "            interactions.append(interaction)\n",
        "\n",
        "        sequences.append({\n",
        "            'user_id': user_id,\n",
        "            'skill_indices': skill_indices,\n",
        "            'corrects': corrects,\n",
        "            'interactions': interactions,\n",
        "            'length': len(interactions)\n",
        "        })\n",
        "\n",
        "    return sequences\n",
        "\n",
        "# Create sequences\n",
        "print(\"\\nCreating student sequences...\")\n",
        "sequences = create_student_sequences(df_clean, skill_to_idx, num_skills)\n",
        "\n",
        "# Show example sequence\n",
        "print(f\"\\nExample sequence (first student):\")\n",
        "example = sequences[0]\n",
        "print(f\"User ID: {example['user_id']}\")\n",
        "print(f\"Sequence length: {example['length']}\")\n",
        "print(f\"First 5 skills attempted: {example['skill_indices'][:5]}\")\n",
        "print(f\"First 5 responses (0=wrong, 1=correct): {example['corrects'][:5]}\")\n",
        "print(f\"First 5 interaction encodings: {example['interactions'][:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPht-lxO7mZO"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW62OMAt7oKR"
      },
      "source": [
        "# CELL 9: Split Data for Training (Student-Level Split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eV3IUXSR7qwt",
        "outputId": "ae5b3347-3499-4d2c-8434-1d51e09fb426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seeds set to 42\n",
            "Dataset splits (matching paper):\n",
            "- Train: 2902 students (80%)\n",
            "- Test: 726 students (20%)\n",
            "\n",
            "Total interactions per split:\n",
            "- Train: 206,543\n",
            "- Test: 51,610\n",
            "\n",
            "Data preprocessing complete! Saved to 'sakt_preprocessed_data.pkl'\n"
          ]
        }
      ],
      "source": [
        "# CELL 9: Split Data for Training (Student-Level Split)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# SET SEED\n",
        "set_seeds(42)\n",
        "\n",
        "# Split at student level (not interaction level) to prevent data leakage\n",
        "# Each student's full sequence goes into either train, val, or test\n",
        "\n",
        "# Use 80/20 split as in the paper (no separate validation)\n",
        "train_sequences, test_sequences = train_test_split(\n",
        "    sequences,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# For hyperparameter tuning, create a small validation set from training\n",
        "#train_sequences, val_sequences = train_test_split(\n",
        "#    train_sequences,\n",
        "#    test_size=0.1,  # 10% of training data for validation\n",
        "#    random_state=42\n",
        "#)\n",
        "\n",
        "print(f\"Dataset splits (matching paper):\")\n",
        "print(f\"- Train: {len(train_sequences)} students (80%)\")\n",
        "#print(f\"- Val: {len(val_sequences)} students\")\n",
        "print(f\"- Test: {len(test_sequences)} students (20%)\")\n",
        "\n",
        "# Calculate total interactions per split\n",
        "train_interactions = sum(seq['length'] for seq in train_sequences)\n",
        "#val_interactions = sum(seq['length'] for seq in val_sequences)\n",
        "test_interactions = sum(seq['length'] for seq in test_sequences)\n",
        "\n",
        "print(f\"\\nTotal interactions per split:\")\n",
        "print(f\"- Train: {train_interactions:,}\")\n",
        "#print(f\"- Val: {val_interactions:,}\")\n",
        "print(f\"- Test: {test_interactions:,}\")\n",
        "\n",
        "# Save the processed data\n",
        "import pickle\n",
        "# For compatibility with SAKT paper, using training data as validation\n",
        "save_data = {\n",
        "    'train': train_sequences,\n",
        "    'val': train_sequences, #change to val_sequences when you want to create a validation data. currently I am using trainin data as validation data for compatibility with the theSAKT paper\n",
        "    'test': test_sequences,\n",
        "    'num_skills': num_skills,\n",
        "    'skill_to_idx': skill_to_idx\n",
        "}\n",
        "\n",
        "with open('sakt_preprocessed_data.pkl', 'wb') as f:\n",
        "    pickle.dump(save_data, f)\n",
        "\n",
        "print(\"\\nData preprocessing complete! Saved to 'sakt_preprocessed_data.pkl'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bc978b60-7425-46a5-d1cb-aeb79cd85510",
        "id": "SOsfeLHG7D51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seeds set to 42\n",
            "Dataset splits (matching paper):\n",
            "- Train: 2902 students (80%)\n",
            "- Test: 726 students (20%)\n",
            "\n",
            "Total interactions per split:\n",
            "- Train: 206,543\n",
            "- Test: 51,610\n",
            "\n",
            "Data preprocessing complete! Saved to 'sakt_preprocessed_data.pkl'\n"
          ]
        }
      ],
      "source": [
        "# CELL 9: Split Data for Training (Student-Level Split)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# SET SEED\n",
        "set_seeds(42)\n",
        "\n",
        "# Split at student level (not interaction level) to prevent data leakage\n",
        "# Each student's full sequence goes into either train, val, or test\n",
        "\n",
        "# Use 80/20 split as in the paper (no separate validation)\n",
        "train_sequences, test_sequences = train_test_split(\n",
        "    sequences,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# For hyperparameter tuning, create a small validation set from training\n",
        "#train_sequences, val_sequences = train_test_split(\n",
        "#    train_sequences,\n",
        "#    test_size=0.1,  # 10% of training data for validation\n",
        "#    random_state=42\n",
        "#)\n",
        "\n",
        "print(f\"Dataset splits (matching paper):\")\n",
        "print(f\"- Train: {len(train_sequences)} students (80%)\")\n",
        "#print(f\"- Val: {len(val_sequences)} students\")\n",
        "print(f\"- Test: {len(test_sequences)} students (20%)\")\n",
        "\n",
        "# Calculate total interactions per split\n",
        "train_interactions = sum(seq['length'] for seq in train_sequences)\n",
        "#val_interactions = sum(seq['length'] for seq in val_sequences)\n",
        "test_interactions = sum(seq['length'] for seq in test_sequences)\n",
        "\n",
        "print(f\"\\nTotal interactions per split:\")\n",
        "print(f\"- Train: {train_interactions:,}\")\n",
        "#print(f\"- Val: {val_interactions:,}\")\n",
        "print(f\"- Test: {test_interactions:,}\")\n",
        "\n",
        "# Save the processed data\n",
        "import pickle\n",
        "# For compatibility with SAKT paper, using training data as validation\n",
        "save_data = {\n",
        "    'train': train_sequences,\n",
        "    'val': train_sequences, #change to val_sequences when you want to create a validation data. currently I am using trainin data as validation data for compatibility with the theSAKT paper\n",
        "    'test': test_sequences,\n",
        "    'num_skills': num_skills,\n",
        "    'skill_to_idx': skill_to_idx\n",
        "}\n",
        "\n",
        "with open('sakt_preprocessed_data.pkl', 'wb') as f:\n",
        "    pickle.dump(save_data, f)\n",
        "\n",
        "print(\"\\nData preprocessing complete! Saved to 'sakt_preprocessed_data.pkl'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6ced7e52-31dd-421b-cb40-d5976556168a",
        "id": "4J0JSr1c7D7W"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seeds set to 42\n",
            "Dataset splits (matching paper):\n",
            "- Train: 2902 students (80%)\n",
            "- Test: 726 students (20%)\n",
            "\n",
            "Total interactions per split:\n",
            "- Train: 206,543\n",
            "- Test: 51,610\n",
            "\n",
            "Data preprocessing complete! Saved to 'sakt_preprocessed_data.pkl'\n"
          ]
        }
      ],
      "source": [
        "# CELL 9: Split Data for Training (Student-Level Split)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# SET SEED\n",
        "set_seeds(42)\n",
        "\n",
        "# Split at student level (not interaction level) to prevent data leakage\n",
        "# Each student's full sequence goes into either train, val, or test\n",
        "\n",
        "# Use 80/20 split as in the paper (no separate validation)\n",
        "train_sequences, test_sequences = train_test_split(\n",
        "    sequences,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# For hyperparameter tuning, create a small validation set from training\n",
        "#train_sequences, val_sequences = train_test_split(\n",
        "#    train_sequences,\n",
        "#    test_size=0.1,  # 10% of training data for validation\n",
        "#    random_state=42\n",
        "#)\n",
        "\n",
        "print(f\"Dataset splits (matching paper):\")\n",
        "print(f\"- Train: {len(train_sequences)} students (80%)\")\n",
        "#print(f\"- Val: {len(val_sequences)} students\")\n",
        "print(f\"- Test: {len(test_sequences)} students (20%)\")\n",
        "\n",
        "# Calculate total interactions per split\n",
        "train_interactions = sum(seq['length'] for seq in train_sequences)\n",
        "#val_interactions = sum(seq['length'] for seq in val_sequences)\n",
        "test_interactions = sum(seq['length'] for seq in test_sequences)\n",
        "\n",
        "print(f\"\\nTotal interactions per split:\")\n",
        "print(f\"- Train: {train_interactions:,}\")\n",
        "#print(f\"- Val: {val_interactions:,}\")\n",
        "print(f\"- Test: {test_interactions:,}\")\n",
        "\n",
        "# Save the processed data\n",
        "import pickle\n",
        "# For compatibility with SAKT paper, using training data as validation\n",
        "save_data = {\n",
        "    'train': train_sequences,\n",
        "    'val': train_sequences, #change to val_sequences when you want to create a validation data. currently I am using trainin data as validation data for compatibility with the theSAKT paper\n",
        "    'test': test_sequences,\n",
        "    'num_skills': num_skills,\n",
        "    'skill_to_idx': skill_to_idx\n",
        "}\n",
        "\n",
        "with open('sakt_preprocessed_data.pkl', 'wb') as f:\n",
        "    pickle.dump(save_data, f)\n",
        "\n",
        "print(\"\\nData preprocessing complete! Saved to 'sakt_preprocessed_data.pkl'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "88f339bd-dc39-4dea-981c-5578b1287246",
        "id": "T1AYeV8X7Ktr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seeds set to 42\n",
            "Dataset splits (matching paper):\n",
            "- Train: 2902 students (80%)\n",
            "- Test: 726 students (20%)\n",
            "\n",
            "Total interactions per split:\n",
            "- Train: 206,543\n",
            "- Test: 51,610\n",
            "\n",
            "Data preprocessing complete! Saved to 'sakt_preprocessed_data.pkl'\n"
          ]
        }
      ],
      "source": [
        "# CELL 9: Split Data for raining (Student-Level Split)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# SET SEED\n",
        "set_seeds(42)\n",
        "\n",
        "# Split at student level (not interaction level) to prevent data leakage\n",
        "# Each student's full sequence goes into either train, val, or test\n",
        "\n",
        "# Use 80/20 split as in the paper (no separate validation)\n",
        "train_sequences, test_sequences = train_test_split(\n",
        "    sequences,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# For compatibility with SAKT paper, using training data as validation\n",
        "save_data = {\n",
        "    'train': train_sequences,\n",
        "    'val': train_sequences,\n",
        "    'test': test_sequences,\n",
        "    'num_skills': num_skills,\n",
        "    'skill_to_idx': skill_to_idx\n",
        "}\n",
        "\n",
        "# For hyperparameter tuning, create a small validation set from training\n",
        "#train_sequences, val_sequences = train_test_split(\n",
        "#    train_sequences,\n",
        "#    test_size=0.1,  # 10% of training data for validation\n",
        "#    random_state=42\n",
        "#)\n",
        "\n",
        "print(f\"Dataset splits (matching paper):\")\n",
        "print(f\"- Train: {len(train_sequences)} students (80%)\")\n",
        "#print(f\"- Val: {len(val_sequences)} students\")\n",
        "print(f\"- Test: {len(test_sequences)} students (20%)\")\n",
        "\n",
        "# Calculate total interactions per split\n",
        "train_interactions = sum(seq['length'] for seq in train_sequences)\n",
        "#val_interactions = sum(seq['length'] for seq in val_sequences)\n",
        "test_interactions = sum(seq['length'] for seq in test_sequences)\n",
        "\n",
        "print(f\"\\nTotal interactions per split:\")\n",
        "print(f\"- Train: {train_interactions:,}\")\n",
        "#print(f\"- Val: {val_interactions:,}\")\n",
        "print(f\"- Test: {test_interactions:,}\")\n",
        "\n",
        "# Save the processed data\n",
        "import pickle\n",
        "# For compatibility with SAKT paper, using training data as validation\n",
        "save_data = {\n",
        "    'train': train_sequences,\n",
        "    'val': train_sequences, #change to val_sequences when you want to create a validation data. currently I am using trainin data as validation data for compatibility with the theSAKT paper\n",
        "    'test': test_sequences,\n",
        "    'num_skills': num_skills,\n",
        "    'skill_to_idx': skill_to_idx\n",
        "}\n",
        "\n",
        "with open('sakt_preprocessed_data.pkl', 'wb') as f:\n",
        "    pickle.dump(save_data, f)\n",
        "\n",
        "print(\"\\nData preprocessing complete! Saved to 'sakt_preprocessed_data.pkl'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzMvcACxEkYx"
      },
      "source": [
        "# CELL 10: SAKT Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YYZUAsjHEmZQ",
        "outputId": "f8f93822-2a09-4105-e549-bc35a507b406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing SAKT model...\n",
            "Model output shape: torch.Size([2, 50])\n",
            "Output range: [0.192, 0.826]\n",
            "Model parameters: 265,101\n"
          ]
        }
      ],
      "source": [
        "# CELL 10: SAKT Model Implementation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F #importing the functional module from PyTorch's torch.nn package, and giving it a shorter alias: F.\n",
        "import math\n",
        "\n",
        "class SAKT(nn.Module):\n",
        "    def __init__(self, num_skills, embed_dim=100, num_heads=5, dropout=0.2):\n",
        "        \"\"\"\n",
        "        SAKT Model matching the paper implementation\n",
        "\n",
        "        Args:\n",
        "            num_skills: Number of unique skills (145 in this case)\n",
        "            embed_dim: Embedding dimension (paper uses {50, 100, 150, 200})\n",
        "            num_heads: Number of attention heads (paper uses 5)\n",
        "            dropout: Dropout rate (paper uses 0.2)\n",
        "        \"\"\"\n",
        "        super(SAKT, self).__init__()\n",
        "\n",
        "        self.num_skills = num_skills\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # Embedding layers\n",
        "        # Interaction embedding: Maps (skill + correct*num_skills) to vectors\n",
        "        self.interaction_embed = nn.Embedding(\n",
        "            num_skills * 2 + 1,\n",
        "            embed_dim,\n",
        "            padding_idx=num_skills * 2\n",
        "        )\n",
        "\n",
        "        # Exercise/skill embedding: Maps skills to vectors for queries\n",
        "        self.skill_embed = nn.Embedding(\n",
        "            num_skills + 1,\n",
        "            embed_dim,\n",
        "            padding_idx=0\n",
        "            )\n",
        "\n",
        "        # Positional embedding: Adds temporal information\n",
        "        self.pos_embed = nn.Embedding(1000, embed_dim)  # max sequence length\n",
        "\n",
        "        # Multi-head attention layer\n",
        "        self.attention = nn.MultiheadAttention(\n",
        "            embed_dim,\n",
        "            num_heads,\n",
        "            dropout=dropout,\n",
        "            batch_first=True  # Important: batch dimension first\n",
        "        )\n",
        "\n",
        "        # Layer normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        # Feed-forward network\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 4),  # Paper uses 4x hidden size\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(embed_dim * 4, embed_dim)\n",
        "        )\n",
        "\n",
        "        # Output prediction layer\n",
        "        self.pred = nn.Linear(embed_dim, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, interactions, skills):\n",
        "        \"\"\"\n",
        "        Forward pass of SAKT\n",
        "\n",
        "        Args:\n",
        "            interactions: [batch_size, seq_len] - past interactions (skill + correct*num_skills)\n",
        "            skills: [batch_size, seq_len] - skills to predict performance on\n",
        "\n",
        "        Returns:\n",
        "            predictions: [batch_size, seq_len] - probability of correct answer\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = interactions.shape\n",
        "\n",
        "        # Create position indices\n",
        "        positions = torch.arange(seq_len, device=interactions.device).unsqueeze(0).expand(batch_size, -1)\n",
        "\n",
        "        # Embed interactions (for Keys and Values in attention)\n",
        "        interaction_embeds = self.interaction_embed(interactions)\n",
        "\n",
        "        # Embed skills (for Queries in attention)\n",
        "        skill_embeds = self.skill_embed(skills)\n",
        "\n",
        "        # Add positional embeddings\n",
        "        interaction_embeds = interaction_embeds + self.pos_embed(positions)\n",
        "        skill_embeds = skill_embeds + self.pos_embed(positions)\n",
        "\n",
        "        # Create attention mask (causal mask - can't see future)\n",
        "        attn_mask = torch.triu(\n",
        "            torch.ones(seq_len, seq_len, device=interactions.device) * float('-inf'),\n",
        "            diagonal=1\n",
        "        )\n",
        "\n",
        "        # Apply self-attention\n",
        "        # Query: what skill we're predicting\n",
        "        # Key & Value: past interaction history\n",
        "        attended, _ = self.attention(\n",
        "            query=skill_embeds,\n",
        "            key=interaction_embeds,\n",
        "            value=interaction_embeds,\n",
        "            attn_mask=attn_mask,\n",
        "            need_weights=False\n",
        "        )\n",
        "\n",
        "        # Residual connection and layer norm\n",
        "        attended = self.layer_norm1(skill_embeds + self.dropout(attended))\n",
        "\n",
        "        # Feed-forward network with residual\n",
        "        ffn_out = self.ffn(attended)\n",
        "        ffn_out = self.layer_norm2(attended + self.dropout(ffn_out))\n",
        "\n",
        "        # Predict probability of correct answer\n",
        "        pred = self.pred(ffn_out).squeeze(-1)\n",
        "        return torch.sigmoid(pred)\n",
        "\n",
        "# Test the model\n",
        "print(\"Testing SAKT model...\")\n",
        "model = SAKT(num_skills=145)\n",
        "\n",
        "# Create dummy batch\n",
        "batch_interactions = torch.randint(0, 290, (2, 50))  # 2 sequences, length 50\n",
        "batch_skills = torch.randint(0, 145, (2, 50))\n",
        "\n",
        "# Forward pass\n",
        "output = model(batch_interactions, batch_skills)\n",
        "print(f\"Model output shape: {output.shape}\")\n",
        "print(f\"Output range: [{output.min():.3f}, {output.max():.3f}]\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aIb8Y30EtBq"
      },
      "source": [
        "# CELL 11: Create PyTorch Dataset and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RnIpiDMGEvyu",
        "outputId": "7853756b-b48b-48c1-b426-6e39ab29b34f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch keys: dict_keys(['interactions', 'skills', 'targets', 'mask'])\n",
            "Interactions shape: torch.Size([128, 100])\n",
            "Skills shape: torch.Size([128, 100])\n",
            "Targets shape: torch.Size([128, 100])\n",
            "Mask shape: torch.Size([128, 100])\n"
          ]
        }
      ],
      "source": [
        "# CELL 11: Create PyTorch Dataset and DataLoaders\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class SAKTDataset(Dataset):\n",
        "    \"\"\"Dataset class for SAKT - Corrected version\"\"\"\n",
        "\n",
        "    def __init__(self, sequences, max_seq_len=100, num_skills=145):\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.num_skills = num_skills\n",
        "        self.padding_interaction = num_skills * 2  # Padding token\n",
        "\n",
        "        # Process sequences: split long ones\n",
        "        self.data = []\n",
        "        for seq in sequences:\n",
        "            interactions = seq['interactions']\n",
        "            skills = seq['skill_indices']\n",
        "            corrects = seq['corrects']\n",
        "\n",
        "            # If sequence is longer than max_seq_len, split it\n",
        "            if len(interactions) > max_seq_len:\n",
        "                for i in range(0, len(interactions), max_seq_len):\n",
        "                    end_idx = min(i + max_seq_len, len(interactions))\n",
        "                    self.data.append({\n",
        "                        'interactions': interactions[i:end_idx],\n",
        "                        'skills': skills[i:end_idx],\n",
        "                        'corrects': corrects[i:end_idx]\n",
        "                    })\n",
        "            else:\n",
        "                self.data.append({\n",
        "                    'interactions': interactions,\n",
        "                    'skills': skills,\n",
        "                    'corrects': corrects\n",
        "                })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.data[idx]\n",
        "        seq_len = len(seq['interactions'])\n",
        "\n",
        "        interactions = list(seq['interactions'])\n",
        "        skills = list(seq['skills'])\n",
        "        corrects = list(seq['corrects'])\n",
        "\n",
        "        shifted_interactions = []\n",
        "        for i in range(seq_len):\n",
        "            if i == 0:\n",
        "                # First position: use a special START token (same as padding)\n",
        "                shifted_interactions.append(self.padding_interaction)\n",
        "            else:\n",
        "                # Use the PREVIOUS interaction\n",
        "                shifted_interactions.append(interactions[i-1])\n",
        "\n",
        "        # Use shifted_interactions instead of interactions\n",
        "        interactions = shifted_interactions\n",
        "\n",
        "        # Pad to the LEFT if sequence is shorter than max_seq_len\n",
        "        if seq_len < self.max_seq_len:\n",
        "            pad_len = self.max_seq_len - seq_len\n",
        "\n",
        "            # Pad to the LEFT\n",
        "            interactions = [self.padding_interaction] * pad_len + interactions\n",
        "            skills = [0] * pad_len + skills  # 0 for padding\n",
        "            corrects = [0] * pad_len + corrects\n",
        "\n",
        "            # Create mask (0 for padding, 1 for real data)\n",
        "            mask = [0] * pad_len + [1] * seq_len\n",
        "        else:\n",
        "            mask = [1] * self.max_seq_len\n",
        "\n",
        "        return {\n",
        "            'interactions': torch.tensor(interactions, dtype=torch.long),\n",
        "            'skills': torch.tensor(skills, dtype=torch.long),\n",
        "            'targets': torch.tensor(corrects, dtype=torch.float),\n",
        "            'mask': torch.tensor(mask, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "# Load preprocessed data\n",
        "import pickle\n",
        "with open('sakt_preprocessed_data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SAKTDataset(data['train'], max_seq_len=100, num_skills=data['num_skills']) # paper uses max_seq_length = 100 and 50\n",
        "val_dataset = SAKTDataset(data['val'], max_seq_len=100, num_skills=data['num_skills'])     # paper uses max_seq_length = 100 and 50\n",
        "test_dataset = SAKTDataset(data['test'], max_seq_len=100, num_skills=data['num_skills'])   # paper uses max_seq_length = 100 and 50\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)  # paper uses batch_size = 128\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)     # paper uses batch_size = 128\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)   # paper uses batch_size = 128\n",
        "\n",
        "# Test dataloader\n",
        "batch = next(iter(train_loader))\n",
        "print(f\"Batch keys: {batch.keys()}\")\n",
        "print(f\"Interactions shape: {batch['interactions'].shape}\")\n",
        "print(f\"Skills shape: {batch['skills'].shape}\")\n",
        "print(f\"Targets shape: {batch['targets'].shape}\")\n",
        "print(f\"Mask shape: {batch['mask'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3iDyuwvE2GR"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBUnkJ5uE4Ox"
      },
      "source": [
        "# CELL 12: Test Data Loaders and Verify Data Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Oho9RKT4E5QD",
        "outputId": "b6db3700-d34f-432f-df33-3a0224fe8b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded data with 145 unique skills\n",
            "\n",
            "Dataset sizes:\n",
            "Train: 4104 students\n",
            "Val: 4104 students\n",
            "Test: 1029 students\n",
            "\n",
            "Testing data loader with one batch:\n",
            "Batch contains: ['interactions', 'skills', 'targets', 'mask']\n",
            "Interactions shape: torch.Size([128, 100])\n",
            "Skills shape: torch.Size([128, 100])\n",
            "Targets shape: torch.Size([128, 100])\n",
            "Mask shape: torch.Size([128, 100])\n",
            "\n",
            "Example from first student in batch:\n",
            "Actual sequence length: 24\n",
            "First 5 interactions: [290, 290, 290, 290, 290]\n",
            "First 5 skills to predict: [0, 0, 0, 0, 0]\n",
            "First 5 correct/incorrect: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "First 5 mask values: [0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "# CELL 12: Test Data Loaders and Verify Data Format\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Load the preprocessed data we saved in Cell 9\n",
        "# 'rb' means read in binary mode (pickle files are binary)\n",
        "with open('sakt_preprocessed_data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)  # Converts file back to Python dictionary\n",
        "\n",
        "print(f\"Loaded data with {data['num_skills']} unique skills\")\n",
        "\n",
        "# Create PyTorch datasets from the sequences\n",
        "# SAKTDataset handles padding and creating input/target pairs\n",
        "train_dataset = SAKTDataset(data['train'], max_seq_len=100)\n",
        "val_dataset = SAKTDataset(data['val'], max_seq_len=100)\n",
        "test_dataset = SAKTDataset(data['test'], max_seq_len=100)\n",
        "\n",
        "print(f\"\\nDataset sizes:\")\n",
        "print(f\"Train: {len(train_dataset)} students\")\n",
        "print(f\"Val: {len(val_dataset)} students\")\n",
        "print(f\"Test: {len(test_dataset)} students\")\n",
        "\n",
        "# Create data loaders that will feed batches to my model\n",
        "# batch_size=128 means process 128 students at once\n",
        "# shuffle=True randomizes order each epoch (important for training)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Test by loading one batch to verify everything works\n",
        "print(f\"\\nTesting data loader with one batch:\")\n",
        "batch = next(iter(train_loader))  # Get first batch\n",
        "\n",
        "# Check what's in each batch\n",
        "print(f\"Batch contains: {list(batch.keys())}\")\n",
        "print(f\"Interactions shape: {batch['interactions'].shape}\")\n",
        "print(f\"Skills shape: {batch['skills'].shape}\")\n",
        "print(f\"Targets shape: {batch['targets'].shape}\")\n",
        "print(f\"Mask shape: {batch['mask'].shape}\")\n",
        "\n",
        "# Look at one student's data to understand format\n",
        "print(f\"\\nExample from first student in batch:\")\n",
        "first_seq_len = batch['mask'][0].sum().int()  # Count non-padded positions\n",
        "print(f\"Actual sequence length: {first_seq_len}\")\n",
        "print(f\"First 5 interactions: {batch['interactions'][0][:5].tolist()}\")\n",
        "print(f\"First 5 skills to predict: {batch['skills'][0][:5].tolist()}\")\n",
        "print(f\"First 5 correct/incorrect: {batch['targets'][0][:5].tolist()}\")\n",
        "print(f\"First 5 mask values: {batch['mask'][0][:5].tolist()}\")  # 1=real, 0=padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSAwA5DuE7nl"
      },
      "source": [
        "# CELL 13: Training Functions for SAKT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "y6BM04A2E-iF"
      },
      "outputs": [],
      "source": [
        "# CELL 13: Training Functions for SAKT\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch\n",
        "\n",
        "    Args:\n",
        "        model: SAKT model\n",
        "        train_loader: DataLoader with training data\n",
        "        optimizer: Adam optimizer\n",
        "        criterion: BCELoss function\n",
        "        device: cuda or cpu\n",
        "\n",
        "    Returns:\n",
        "        epoch_loss: Average loss for this epoch\n",
        "        epoch_auc: AUC score for this epoch\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Progress bar to track training\n",
        "    pbar = tqdm(train_loader, desc='Training', leave=False)\n",
        "\n",
        "    for batch in pbar:\n",
        "        # Move all tensors to GPU if available\n",
        "        interactions = batch['interactions'].to(device)\n",
        "        skills = batch['skills'].to(device)\n",
        "        targets = batch['targets'].to(device)\n",
        "        mask = batch['mask'].to(device)\n",
        "\n",
        "        # Clear gradients from previous batch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: get predictions from model\n",
        "        predictions = model(interactions, skills)\n",
        "\n",
        "        # Calculate loss only on non-padded positions\n",
        "        # criterion returns loss for each position\n",
        "        # Compute loss with masking\n",
        "        loss = criterion(predictions, targets)  # This gives loss per element\n",
        "        masked_loss = (loss * mask).sum() / mask.sum()  # Apply mask\n",
        "\n",
        "\n",
        "        # Backward pass: compute gradients (backpropagation)\n",
        "        masked_loss.backward()\n",
        "\n",
        "        # Clip gradients to prevent explosion\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        # Update model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Collect predictions for metrics\n",
        "        total_loss += masked_loss.item()\n",
        "\n",
        "        # Calculate AUC only on valid (non-padded) predictions\n",
        "        valid_idx = mask == 1\n",
        "        valid_predictions = predictions[valid_idx].detach().cpu().numpy()\n",
        "        valid_targets = targets[valid_idx].detach().cpu().numpy()\n",
        "\n",
        "        all_predictions.extend(valid_predictions)\n",
        "        all_targets.extend(valid_targets)\n",
        "\n",
        "        # Update progress bar with current loss\n",
        "        pbar.set_postfix({'loss': f'{masked_loss.item():.4f}'})\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = total_loss / len(train_loader)\n",
        "    epoch_auc = roc_auc_score(all_targets, all_predictions)\n",
        "\n",
        "    return epoch_loss, epoch_auc\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Validate the model (no gradient updates)\n",
        "\n",
        "    Args:\n",
        "        model: SAKT model\n",
        "        val_loader: DataLoader with validation data\n",
        "        criterion: BCELoss function\n",
        "        device: cuda or cpu\n",
        "\n",
        "    Returns:\n",
        "        val_loss: Average validation loss\n",
        "        val_auc: Validation AUC score\n",
        "    \"\"\"\n",
        "    model.eval()  # Disable dropout and use batch norm statistics\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # No gradient computation needed for validation\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc='Validating', leave=False):\n",
        "            # Move to device\n",
        "            interactions = batch['interactions'].to(device)\n",
        "            skills = batch['skills'].to(device)\n",
        "            targets = batch['targets'].to(device)\n",
        "            mask = batch['mask'].to(device)\n",
        "\n",
        "            # Get predictions\n",
        "            predictions = model(interactions, skills)\n",
        "\n",
        "            # Calculate loss\n",
        "            # Compute loss with masking\n",
        "            loss = criterion(predictions, targets)  # This gives loss per element\n",
        "            masked_loss = (loss * mask).sum() / mask.sum()  # Apply mask and average\n",
        "\n",
        "            # Collect for metrics\n",
        "            total_loss += masked_loss.item()\n",
        "\n",
        "            # Extract valid predictions\n",
        "            valid_idx = mask == 1\n",
        "            valid_predictions = predictions[valid_idx].cpu().numpy()\n",
        "            valid_targets = targets[valid_idx].cpu().numpy()\n",
        "\n",
        "            all_predictions.extend(valid_predictions)\n",
        "            all_targets.extend(valid_targets)\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    val_loss = total_loss / len(val_loader)\n",
        "    val_auc = roc_auc_score(all_targets, all_predictions)\n",
        "\n",
        "    return val_loss, val_auc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 13.5: Set Random Seeds for Reproducibility\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seeds(seed=42):\n",
        "    \"\"\"Set seeds for reproducibility\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    print(f\"Random seeds set to {seed}\")\n",
        "\n",
        "# Set seeds before any model training\n",
        "set_seeds(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "f1j7BeHljOfZ",
        "outputId": "c6a1030a-9355-4c19-d8af-1d322d194787"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seeds set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvoiybrsFCFk"
      },
      "source": [
        "# CELL 14: Train SAKT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jqPTIgbjFC37",
        "outputId": "d1294c97-dfb4-4057-da76-e95c56629f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA L4\n",
            "Random seeds set to 42\n",
            "Total parameters: 265,101\n",
            "Trainable parameters: 265,101\n",
            "\n",
            "Starting training for max 30 epochs...\n",
            "============================================================\n",
            "\n",
            "Epoch 1/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.6364, AUC: 0.5772\n",
            "\n",
            "Epoch 2/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.6010, AUC: 0.6701\n",
            "\n",
            "Epoch 3/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5860, AUC: 0.6966\n",
            "\n",
            "Epoch 4/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5781, AUC: 0.7098\n",
            "\n",
            "Epoch 5/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5723, AUC: 0.7185\n",
            "\n",
            "Epoch 6/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5668, AUC: 0.7246\n",
            "\n",
            "Epoch 7/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5638, AUC: 0.7308\n",
            "\n",
            "Epoch 8/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5602, AUC: 0.7337\n",
            "\n",
            "Epoch 9/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5577, AUC: 0.7381\n",
            "\n",
            "Epoch 10/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5537, AUC: 0.7421\n",
            "\n",
            "Epoch 11/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5537, AUC: 0.7433\n",
            "\n",
            "Epoch 12/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5494, AUC: 0.7451\n",
            "\n",
            "Epoch 13/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5479, AUC: 0.7475\n",
            "\n",
            "Epoch 14/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5476, AUC: 0.7500\n",
            "\n",
            "Epoch 15/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5449, AUC: 0.7518\n",
            "\n",
            "Epoch 16/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5461, AUC: 0.7530\n",
            "\n",
            "Epoch 17/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5437, AUC: 0.7546\n",
            "\n",
            "Epoch 18/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5438, AUC: 0.7559\n",
            "\n",
            "Epoch 19/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5420, AUC: 0.7565\n",
            "\n",
            "Epoch 20/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5399, AUC: 0.7585\n",
            "\n",
            "Epoch 21/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5401, AUC: 0.7597\n",
            "\n",
            "Epoch 22/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5400, AUC: 0.7586\n",
            "\n",
            "Epoch 23/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5390, AUC: 0.7614\n",
            "\n",
            "Epoch 24/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5358, AUC: 0.7623\n",
            "\n",
            "Epoch 25/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5386, AUC: 0.7607\n",
            "\n",
            "Epoch 26/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5347, AUC: 0.7636\n",
            "\n",
            "Epoch 27/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5371, AUC: 0.7637\n",
            "\n",
            "Epoch 28/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5376, AUC: 0.7616\n",
            "\n",
            "Epoch 29/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5353, AUC: 0.7649\n",
            "\n",
            "Epoch 30/30\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 0.5348, AUC: 0.7651\n",
            "âœ“ Final model saved! (Train AUC: 0.7651)\n",
            "\n",
            "Training complete!\n",
            "Final training AUC: 0.7651\n"
          ]
        }
      ],
      "source": [
        "# CELL 14: Train SAKT Model\n",
        "\n",
        "# Check if GPU is available and use it\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# SET SEED\n",
        "set_seeds(42)\n",
        "\n",
        "# Initialize model with paper's hyperparameters\n",
        "model = SAKT(\n",
        "    num_skills=num_skills,  # From my dataset analysis\n",
        "    embed_dim=100,   # Paper: d=[50, 100, 150, 200]\n",
        "    num_heads=5,     # Paper: h=5\n",
        "    dropout=0.2      # Paper: dropout=0.2 or 0.3\n",
        ").to(device)\n",
        "\n",
        "# Count model parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Initialize optimizer (Adam with paper's learning rate)\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=0.001,           # Paper uses 0.001\n",
        "    weight_decay=0.0001  # L2 regularization\n",
        ")\n",
        "\n",
        "# Loss function for binary classification\n",
        "# reduction='none' returns loss per element (needed for masking)\n",
        "criterion = nn.BCELoss(reduction='none')\n",
        "\n",
        "\n",
        "# Training configuration\n",
        "NUM_EPOCHS = 30\n",
        "\n",
        "# Track metrics for visualization\n",
        "history = {\n",
        "    'train_loss': [], 'train_auc': [],\n",
        "}\n",
        "\n",
        "print(f\"\\nStarting training for max {NUM_EPOCHS} epochs...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Train for one epoch\n",
        "    train_loss, train_auc = train_epoch(\n",
        "        model, train_loader, optimizer, criterion, device\n",
        "    )\n",
        "\n",
        "\n",
        "    # Store history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_auc'].append(train_auc)\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Train - Loss: {train_loss:.4f}, AUC: {train_auc:.4f}\")\n",
        "\n",
        "\n",
        "    if epoch + 1 == NUM_EPOCHS:\n",
        "        # Save checkpoint\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_auc': train_auc,\n",
        "            'history': history\n",
        "        }\n",
        "        torch.save(checkpoint, 'best_sakt_model.pth')\n",
        "        print(f\"âœ“ Final model saved! (Train AUC: {train_auc:.4f})\")\n",
        "\n",
        "print(f\"\\nTraining complete!\")\n",
        "print(f\"Final training AUC: {train_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qt2FatlFKDk"
      },
      "source": [
        "# CELL 16: Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fpUEBkydFMc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c3abda0f-1d2b-4127-ecab-b18c162d5823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Set Results:\n",
            "Test Loss: 0.5447\n",
            "Test AUC: 0.7320\n",
            "\n",
            "Generalization check:\n",
            "Test AUC: 0.7320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Additional Test Metrics:\n",
            "Accuracy: 0.7230\n",
            "Precision: 0.7439\n",
            "Recall: 0.8922\n"
          ]
        }
      ],
      "source": [
        "# CELL 16: Evaluate on Test Set\n",
        "\n",
        "# Load best model\n",
        "checkpoint = torch.load('best_sakt_model.pth', weights_only=False)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "test_loss, test_auc = validate_epoch(model, test_loader, criterion, device)\n",
        "\n",
        "print(f\"\\nTest Set Results:\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "# Compare with validation performance\n",
        "print(f\"\\nGeneralization check:\")\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "# Additional metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Get predictions for additional metrics\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        interactions = batch['interactions'].to(device)\n",
        "        skills = batch['skills'].to(device)\n",
        "        targets = batch['targets'].to(device)\n",
        "        mask = batch['mask'].to(device)\n",
        "\n",
        "        predictions = model(interactions, skills)\n",
        "\n",
        "        # Get actual batch size (last batch might be smaller)\n",
        "        current_batch_size = interactions.shape[0]\n",
        "\n",
        "        # Extract valid predictions for each sequence in batch\n",
        "        for i in range(current_batch_size):\n",
        "            mask_i = mask[i].cpu().numpy()\n",
        "            pred_i = predictions[i].cpu().numpy()\n",
        "            target_i = targets[i].cpu().numpy()\n",
        "\n",
        "            # Only add non-padded values\n",
        "            valid_idx = mask_i == 1\n",
        "            all_predictions.extend(pred_i[valid_idx].tolist())\n",
        "            all_targets.extend(target_i[valid_idx].tolist())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "all_predictions = np.array(all_predictions)\n",
        "all_targets = np.array(all_targets)\n",
        "\n",
        "# Calculate additional metrics using 0.5 threshold\n",
        "binary_predictions = (all_predictions > 0.5).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(all_targets, binary_predictions)\n",
        "precision = precision_score(all_targets, binary_predictions)\n",
        "recall = recall_score(all_targets, binary_predictions)\n",
        "#f1 = f1_score(all_targets, binary_predictions)\n",
        "\n",
        "print(f\"\\nAdditional Test Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tG8IQBhjCUfS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ef98e344-474f-4f83-a08f-1e4a58b7d10c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available columns in ASSIST2009:\n",
            "['Unnamed: 0', 'order_id', 'assignment_id', 'user_id', 'assistment_id', 'problem_id', 'original', 'correct', 'attempt_count', 'ms_first_response', 'tutor_mode', 'answer_type', 'sequence_id', 'student_class_id', 'position', 'type', 'base_sequence_id', 'skill_id', 'skill_name', 'teacher_id', 'school_id', 'hint_count', 'hint_total', 'overlap_time', 'template_id', 'answer_id', 'answer_text', 'first_action', 'bottom_hint', 'opportunity', 'opportunity_original']\n",
            "\n",
            "Available enhancement features: ['ms_first_response', 'hint_count', 'attempt_count', 'overlap_time']\n",
            "ms_first_response: 0.0% missing\n",
            "hint_count: 0.0% missing\n",
            "attempt_count: 0.0% missing\n",
            "overlap_time: 0.0% missing\n"
          ]
        }
      ],
      "source": [
        "# CELL 17: Examine Available Features for Enhancement\n",
        "\n",
        "# Load your data and check columns\n",
        "print(\"Available columns in ASSIST2009:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Check for key features we want to use\n",
        "key_features = ['ms_first_response', 'hint_count', 'attempt_count', 'overlap_time']\n",
        "available_features = [f for f in key_features if f in df.columns]\n",
        "print(f\"\\nAvailable enhancement features: {available_features}\")\n",
        "\n",
        "# Check data completeness for these features\n",
        "for feature in available_features:\n",
        "    if feature in df.columns:\n",
        "        missing_pct = df[feature].isna().sum() / len(df) * 100\n",
        "        print(f\"{feature}: {missing_pct:.1f}% missing\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 18: Enhanced Data Preprocessing (3 Features Only)\n",
        "\n",
        "def create_enhanced_sequences(df_clean, skill_to_idx, num_skills):\n",
        "    \"\"\"Create sequences with 3 Behavioral features (no scaffold)\"\"\"\n",
        "    sequences = []\n",
        "\n",
        "    for user_id, user_data in df_clean.groupby('user_id'):\n",
        "        # Basic features\n",
        "        skills = user_data['skill_id'].values\n",
        "        corrects = user_data['correct'].values\n",
        "        skill_indices = [skill_to_idx[skill] for skill in skills]\n",
        "\n",
        "        # Enhanced features (3 only)\n",
        "        # 1. Response time (normalize to 0-1 range)\n",
        "        if 'ms_first_response' in user_data.columns:\n",
        "            response_times = user_data['ms_first_response'].fillna(user_data['ms_first_response'].median()).values\n",
        "            response_times = np.clip(response_times, 0, 300000) / 300000.0\n",
        "        else:\n",
        "            response_times = np.ones(len(skills)) * 0.5\n",
        "\n",
        "        # 2. Hint usage (normalize by max hints)\n",
        "        if 'hint_count' in user_data.columns:\n",
        "            hint_counts = user_data['hint_count'].fillna(0).values\n",
        "            hint_counts = np.clip(hint_counts, 0, 5) / 5.0\n",
        "        else:\n",
        "            hint_counts = np.zeros(len(skills))\n",
        "\n",
        "        # 3. Attempt count\n",
        "        if 'attempt_count' in user_data.columns:\n",
        "            attempt_counts = user_data['attempt_count'].fillna(1).values\n",
        "            attempt_counts = np.clip(attempt_counts, 1, 5) / 5.0\n",
        "        else:\n",
        "            attempt_counts = np.ones(len(skills)) * 0.2\n",
        "\n",
        "        # Create interactions\n",
        "        interactions = []\n",
        "        for skill_idx, correct in zip(skill_indices, corrects):\n",
        "            interaction = skill_idx + (correct * num_skills)\n",
        "            interactions.append(interaction)\n",
        "\n",
        "        sequences.append({\n",
        "            'user_id': user_id,\n",
        "            'skill_indices': skill_indices,\n",
        "            'corrects': corrects,\n",
        "            'interactions': interactions,\n",
        "            'response_times': response_times,\n",
        "            'hint_counts': hint_counts,\n",
        "            'attempt_counts': attempt_counts,\n",
        "            'length': len(interactions)\n",
        "        })\n",
        "\n",
        "    return sequences\n",
        "\n",
        "# Create enhanced sequences\n",
        "print(\"Creating enhanced sequences...\")\n",
        "enhanced_sequences = create_enhanced_sequences(df_clean, skill_to_idx, num_skills)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# SET SEED\n",
        "set_seeds(42)\n",
        "\n",
        "train_sequences_enh, test_sequences_enh = train_test_split(\n",
        "    enhanced_sequences,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Enhanced sequences created:\")\n",
        "print(f\"- Train: {len(train_sequences_enh)} students\")\n",
        "print(f\"- Test: {len(test_sequences_enh)} students\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-ZY2wNNOj4Bf",
        "outputId": "874d82cf-f7a3-4058-95f8-0b7462cd12ec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating enhanced sequences...\n",
            "Random seeds set to 42\n",
            "Enhanced sequences created:\n",
            "- Train: 2902 students\n",
            "- Test: 726 students\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "14ir5gkkCjyb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d41e925d-bc1e-4f2b-bf8f-c05a4d0d0f64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Behavioral-Aware SAKT...\n",
            "Enhanced model parameters: 298,002\n"
          ]
        }
      ],
      "source": [
        "# CELL 19: Behavioral-Aware SAKT Model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BehavioralAwareSAKT(nn.Module):\n",
        "    def __init__(self, num_skills, embed_dim=100, num_heads=5, dropout=0.2, num_features=3):\n",
        "        \"\"\"\n",
        "        Enhanced SAKT with Behavioral awareness and multi-feature integration\n",
        "\n",
        "        Args:\n",
        "            num_features: Number of additional features (response_time, hints, attempts)\n",
        "        \"\"\"\n",
        "        super(BehavioralAwareSAKT, self).__init__()\n",
        "\n",
        "        self.num_skills = num_skills\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # Original SAKT embeddings\n",
        "        self.interaction_embed = nn.Embedding(\n",
        "            num_skills * 2 + 1,\n",
        "            embed_dim,\n",
        "            padding_idx=num_skills * 2\n",
        "        )\n",
        "        self.skill_embed = nn.Embedding(\n",
        "            num_skills + 1,\n",
        "            embed_dim,\n",
        "            padding_idx=0\n",
        "        )\n",
        "        self.pos_embed = nn.Embedding(1000, embed_dim)\n",
        "\n",
        "        # Feature embeddings (New)\n",
        "        self.feature_proj = nn.Linear(num_features, embed_dim // 4)\n",
        "\n",
        "        # Behavioral-aware projection (New)\n",
        "        self.Behavioral_proj = nn.Linear(embed_dim + embed_dim // 4, embed_dim)\n",
        "\n",
        "        # Enhanced attention with Behavioral awareness\n",
        "        self.attention = nn.MultiheadAttention(\n",
        "            embed_dim,\n",
        "            num_heads,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Sparse attention gate (learns which interactions to focus on) (New)\n",
        "        self.attention_gate = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embed_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Layer normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        # Feed-forward network\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(embed_dim * 4, embed_dim)\n",
        "        )\n",
        "\n",
        "        # Output prediction with Behavioral awareness\n",
        "        self.pred = nn.Linear(embed_dim, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, interactions, skills, features):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            interactions: [batch_size, seq_len]\n",
        "            skills: [batch_size, seq_len]\n",
        "            features: [batch_size, seq_len, num_features] - response_time, hints, attempts\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = interactions.shape\n",
        "\n",
        "        # Position indices\n",
        "        positions = torch.arange(seq_len, device=interactions.device).unsqueeze(0).expand(batch_size, -1)\n",
        "\n",
        "        # Embed interactions and skills\n",
        "        interaction_embeds = self.interaction_embed(interactions)\n",
        "        skill_embeds = self.skill_embed(skills)\n",
        "\n",
        "        # NEW: Project features and combine with embeddings\n",
        "        feature_embeds = self.feature_proj(features)  # [batch, seq_len, embed_dim//4]\n",
        "\n",
        "        # Enhance interaction embeddings with features (Behavioral-aware)\n",
        "        enhanced_interactions = torch.cat([interaction_embeds, feature_embeds], dim=-1)\n",
        "        enhanced_interactions = self.Behavioral_proj(enhanced_interactions)\n",
        "\n",
        "        # Add positional embeddings\n",
        "        enhanced_interactions = enhanced_interactions + self.pos_embed(positions)\n",
        "        skill_embeds = skill_embeds + self.pos_embed(positions)\n",
        "\n",
        "        # Causal mask\n",
        "        attn_mask = torch.triu(\n",
        "            torch.ones(seq_len, seq_len, device=interactions.device) * float('-inf'),\n",
        "            diagonal=1\n",
        "        )\n",
        "\n",
        "        # Apply attention\n",
        "        attended, attn_weights = self.attention(\n",
        "            query=skill_embeds,\n",
        "            key=enhanced_interactions,\n",
        "            value=enhanced_interactions,\n",
        "            attn_mask=attn_mask,\n",
        "            need_weights=True\n",
        "        )\n",
        "\n",
        "        # NEW: Apply sparse attention gate\n",
        "        gate_input = torch.cat([skill_embeds, attended], dim=-1)\n",
        "        gate_weights = self.attention_gate(gate_input)\n",
        "        attended = attended * gate_weights\n",
        "\n",
        "        # Residual connection and layer norm\n",
        "        attended = self.layer_norm1(skill_embeds + self.dropout(attended))\n",
        "\n",
        "        # Feed-forward network\n",
        "        ffn_out = self.ffn(attended)\n",
        "        ffn_out = self.layer_norm2(attended + self.dropout(ffn_out))\n",
        "\n",
        "        # Predict\n",
        "        pred = self.pred(ffn_out).squeeze(-1)\n",
        "        return torch.sigmoid(pred)\n",
        "\n",
        "# Test the enhanced model\n",
        "print(\"Testing Behavioral-Aware SAKT...\")\n",
        "model_enhanced = BehavioralAwareSAKT(num_skills=145)\n",
        "print(f\"Enhanced model parameters: {sum(p.numel() for p in model_enhanced.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "t96ORb09Cq2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "75b1dd6a-3418-4929-c68b-b99242ed4179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced datasets created:\n",
            "Train batches: 33\n",
            "Test batches: 9\n"
          ]
        }
      ],
      "source": [
        "# CELL 20: Enhanced Dataset for BA-SAKT\n",
        "\n",
        "class EnhancedSAKTDataset(Dataset):\n",
        "    def __init__(self, sequences, max_seq_len=100, num_skills=145):\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.num_skills = num_skills\n",
        "        self.padding_interaction = num_skills * 2\n",
        "\n",
        "        # Process sequences\n",
        "        self.data = []\n",
        "        for seq in sequences:\n",
        "            if len(seq['interactions']) > max_seq_len:\n",
        "                # Split long sequences\n",
        "                for i in range(0, len(seq['interactions']), max_seq_len):\n",
        "                    end_idx = min(i + max_seq_len, len(seq['interactions']))\n",
        "                    self.data.append({\n",
        "                        'interactions': seq['interactions'][i:end_idx],\n",
        "                        'skills': seq['skill_indices'][i:end_idx],\n",
        "                        'corrects': seq['corrects'][i:end_idx],\n",
        "                        'response_times': seq['response_times'][i:end_idx],\n",
        "                        'hint_counts': seq['hint_counts'][i:end_idx],\n",
        "                        'attempt_counts': seq['attempt_counts'][i:end_idx]\n",
        "\n",
        "                    })\n",
        "            else:\n",
        "                self.data.append({\n",
        "                    'interactions': seq['interactions'],\n",
        "                    'skills': seq['skill_indices'],\n",
        "                    'corrects': seq['corrects'],\n",
        "                    'response_times': seq['response_times'],\n",
        "                    'hint_counts': seq['hint_counts'],\n",
        "                    'attempt_counts': seq['attempt_counts']\n",
        "                })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.data[idx]\n",
        "        seq_len = len(seq['interactions'])\n",
        "\n",
        "        # Convert to lists and apply shifting\n",
        "        interactions = list(seq['interactions'])\n",
        "        skills = list(seq['skills'])\n",
        "        corrects = list(seq['corrects'])\n",
        "        response_times = list(seq['response_times'])\n",
        "        hint_counts = list(seq['hint_counts'])\n",
        "        attempt_counts = list(seq['attempt_counts'])\n",
        "\n",
        "        # Shift interactions\n",
        "        shifted_interactions = []\n",
        "        shifted_features = []\n",
        "        for i in range(seq_len):\n",
        "            if i == 0:\n",
        "                shifted_interactions.append(self.padding_interaction)\n",
        "                shifted_features.append([0.5, 0.0, 0.2])  # Default features\n",
        "            else:\n",
        "                shifted_interactions.append(interactions[i-1])\n",
        "                shifted_features.append([\n",
        "                    response_times[i-1],\n",
        "                    hint_counts[i-1],\n",
        "                    attempt_counts[i-1]\n",
        "                ])\n",
        "\n",
        "        interactions = shifted_interactions\n",
        "        features = shifted_features\n",
        "\n",
        "        # Pad to the LEFT\n",
        "        if seq_len < self.max_seq_len:\n",
        "            pad_len = self.max_seq_len - seq_len\n",
        "\n",
        "            interactions = [self.padding_interaction] * pad_len + interactions\n",
        "            skills = [0] * pad_len + skills\n",
        "            corrects = [0] * pad_len + corrects\n",
        "            features = [[0.5, 0.0, 0.2]] * pad_len + features\n",
        "            mask = [0] * pad_len + [1] * seq_len\n",
        "        else:\n",
        "            mask = [1] * self.max_seq_len\n",
        "\n",
        "        return {\n",
        "            'interactions': torch.tensor(interactions, dtype=torch.long),\n",
        "            'skills': torch.tensor(skills, dtype=torch.long),\n",
        "            'targets': torch.tensor(corrects, dtype=torch.float),\n",
        "            'features': torch.tensor(features, dtype=torch.float),\n",
        "            'mask': torch.tensor(mask, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "# Create enhanced datasets\n",
        "train_dataset_enh = EnhancedSAKTDataset(train_sequences_enh, max_seq_len=100, num_skills=num_skills)\n",
        "test_dataset_enh = EnhancedSAKTDataset(test_sequences_enh, max_seq_len=100, num_skills=num_skills)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader_enh = DataLoader(train_dataset_enh, batch_size=128, shuffle=True)\n",
        "test_loader_enh = DataLoader(test_dataset_enh, batch_size=128, shuffle=False)\n",
        "\n",
        "print(f\"Enhanced datasets created:\")\n",
        "print(f\"Train batches: {len(train_loader_enh)}\")\n",
        "print(f\"Test batches: {len(test_loader_enh)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "v1UKWO09CvuQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a58c9b6f-fb84-440a-f939-13b6be53c1b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seeds set to 42\n",
            "Training Behavioral-Aware SAKT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss=0.5479, Train AUC=0.7454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Loss=0.5412, Train AUC=0.7589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: Train Loss=0.5294, Train AUC=0.7674\n",
            "\n",
            "============================================================\n",
            "MODEL COMPARISON\n",
            "============================================================\n",
            "\n",
            "Baseline SAKT:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test AUC: 0.7320\n",
            "\n",
            "Behavioral-Aware SAKT:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test AUC: 0.7393\n",
            "\n",
            "Improvement: +1.00%\n",
            "Absolute gain: +0.0073\n"
          ]
        }
      ],
      "source": [
        "# CELL 21: Train and Compare Models\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "set_seeds(42)\n",
        "\n",
        "# Modified training functions for enhanced model\n",
        "def train_epoch_enhanced(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    for batch in tqdm(train_loader, desc='Training', leave=False):\n",
        "        interactions = batch['interactions'].to(device)\n",
        "        skills = batch['skills'].to(device)\n",
        "        targets = batch['targets'].to(device)\n",
        "        features = batch['features'].to(device)\n",
        "        mask = batch['mask'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass with features\n",
        "        predictions = model(interactions, skills, features)\n",
        "\n",
        "        # Masked loss\n",
        "        loss = criterion(predictions, targets)\n",
        "        masked_loss = (loss * mask).sum() / mask.sum()\n",
        "\n",
        "        masked_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += masked_loss.item()\n",
        "\n",
        "        # Collect predictions\n",
        "        valid_idx = mask == 1\n",
        "        valid_predictions = predictions[valid_idx].detach().cpu().numpy()\n",
        "        valid_targets = targets[valid_idx].detach().cpu().numpy()\n",
        "\n",
        "        all_predictions.extend(valid_predictions)\n",
        "        all_targets.extend(valid_targets)\n",
        "\n",
        "    epoch_loss = total_loss / len(train_loader)\n",
        "    epoch_auc = roc_auc_score(all_targets, all_predictions)\n",
        "\n",
        "    return epoch_loss, epoch_auc\n",
        "\n",
        "# Train enhanced model\n",
        "print(\"Training Behavioral-Aware SAKT...\")\n",
        "model_enhanced = BehavioralAwareSAKT(\n",
        "    num_skills=145,\n",
        "    embed_dim=100,\n",
        "    num_heads=5,\n",
        "    dropout=0.2,\n",
        "    num_features=3\n",
        ").to(device)\n",
        "\n",
        "optimizer_enh = optim.Adam(model_enhanced.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "criterion = nn.BCELoss(reduction='none')\n",
        "\n",
        "# Training loop\n",
        "NUM_EPOCHS = 30\n",
        "best_test_auc = 0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss, train_auc = train_epoch_enhanced(\n",
        "        model_enhanced, train_loader_enh, optimizer_enh, criterion, device\n",
        "    )\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train AUC={train_auc:.4f}\")\n",
        "\n",
        "    # Save final model\n",
        "    if epoch + 1 == NUM_EPOCHS:\n",
        "        torch.save({\n",
        "            'model_state_dict': model_enhanced.state_dict(),\n",
        "            'train_auc': train_auc\n",
        "        }, 'enhanced_sakt_model.pth')\n",
        "\n",
        "# Evaluate both models\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load baseline model\n",
        "baseline_checkpoint = torch.load('best_sakt_model.pth', weights_only=False)\n",
        "model_baseline = SAKT(num_skills=145, embed_dim=100, num_heads=5, dropout=0.2).to(device)\n",
        "model_baseline.load_state_dict(baseline_checkpoint['model_state_dict'])\n",
        "\n",
        "# Evaluate baseline\n",
        "print(\"\\nBaseline SAKT:\")\n",
        "baseline_test_loss, baseline_test_auc = validate_epoch(\n",
        "    model_baseline, test_loader, criterion, device\n",
        ")\n",
        "print(f\"Test AUC: {baseline_test_auc:.4f}\")\n",
        "\n",
        "# Evaluate enhanced model\n",
        "print(\"\\nBehavioral-Aware SAKT:\")\n",
        "# Create a validation function for enhanced model\n",
        "def validate_enhanced(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            interactions = batch['interactions'].to(device)\n",
        "            skills = batch['skills'].to(device)\n",
        "            targets = batch['targets'].to(device)\n",
        "            features = batch['features'].to(device)\n",
        "            mask = batch['mask'].to(device)\n",
        "\n",
        "            predictions = model(interactions, skills, features)\n",
        "\n",
        "            loss = criterion(predictions, targets)\n",
        "            masked_loss = (loss * mask).sum() / mask.sum()\n",
        "            total_loss += masked_loss.item()\n",
        "\n",
        "            valid_idx = mask == 1\n",
        "            valid_predictions = predictions[valid_idx].cpu().numpy()\n",
        "            valid_targets = targets[valid_idx].cpu().numpy()\n",
        "\n",
        "            all_predictions.extend(valid_predictions)\n",
        "            all_targets.extend(valid_targets)\n",
        "\n",
        "    test_loss = total_loss / len(test_loader)\n",
        "    test_auc = roc_auc_score(all_targets, all_predictions)\n",
        "\n",
        "    return test_loss, test_auc\n",
        "\n",
        "enhanced_test_loss, enhanced_test_auc = validate_enhanced(\n",
        "    model_enhanced, test_loader_enh, criterion, device\n",
        ")\n",
        "print(f\"Test AUC: {enhanced_test_auc:.4f}\")\n",
        "\n",
        "# Calculate improvement\n",
        "improvement = (enhanced_test_auc - baseline_test_auc) / baseline_test_auc * 100\n",
        "print(f\"\\nImprovement: {improvement:+.2f}%\")\n",
        "print(f\"Absolute gain: {enhanced_test_auc - baseline_test_auc:+.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 22: Feature Ablation Study. Essential ablations to understand the 1.0% improvement"
      ],
      "metadata": {
        "id": "WSY5PNCK1Wcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 22: Feature Ablation Study\n",
        "\n",
        "print(\"Starting Feature Ablation Study\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Ablation configurations\n",
        "ablation_configs = [\n",
        "    {'name': 'response_time_only', 'features_to_use': [0], 'description': 'Response Time Only'},\n",
        "    {'name': 'hints_only', 'features_to_use': [1], 'description': 'Hints Only'},\n",
        "    {'name': 'attempts_only', 'features_to_use': [2], 'description': 'Attempts Only'},\n",
        "    {'name': 'no_response_time', 'features_to_use': [1, 2], 'description': 'Hints + Attempts (No RT)'},\n",
        "    {'name': 'no_hints', 'features_to_use': [0, 2], 'description': 'RT + Attempts (No Hints)'},\n",
        "    {'name': 'no_attempts', 'features_to_use': [0, 1], 'description': 'RT + Hints (No Attempts)'},\n",
        "]\n",
        "\n",
        "# Store results\n",
        "ablation_results = {}\n",
        "\n",
        "# Run each ablation\n",
        "for config in ablation_configs:\n",
        "    print(f\"\\nTesting: {config['description']}\")\n",
        "\n",
        "    # Create modified dataset that uses only selected features\n",
        "    class AblationDataset(Dataset):\n",
        "        def __init__(self, original_dataset, features_to_use):\n",
        "            self.original_dataset = original_dataset\n",
        "            self.features_to_use = features_to_use\n",
        "            self.num_features = len(features_to_use)\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.original_dataset)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = self.original_dataset[idx]\n",
        "            # Select only specified features\n",
        "            features = item['features']\n",
        "            selected_features = features[:, self.features_to_use]\n",
        "\n",
        "            return {\n",
        "                'interactions': item['interactions'],\n",
        "                'skills': item['skills'],\n",
        "                'targets': item['targets'],\n",
        "                'features': selected_features,\n",
        "                'mask': item['mask']\n",
        "            }\n",
        "\n",
        "    # Create ablation datasets\n",
        "    train_dataset_ablation = AblationDataset(train_dataset_enh, config['features_to_use'])\n",
        "    test_dataset_ablation = AblationDataset(test_dataset_enh, config['features_to_use'])\n",
        "\n",
        "    train_loader_ablation = DataLoader(train_dataset_ablation, batch_size=128, shuffle=True)\n",
        "    test_loader_ablation = DataLoader(test_dataset_ablation, batch_size=128, shuffle=False)\n",
        "\n",
        "    # Train model with fewer features\n",
        "    set_seeds(42)  # Same seed for fair comparison\n",
        "\n",
        "    model_ablation = BehavioralAwareSAKT(\n",
        "        num_skills=num_skills,\n",
        "        embed_dim=100,\n",
        "        num_heads=5,\n",
        "        dropout=0.2,\n",
        "        num_features=len(config['features_to_use'])\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model_ablation.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "    # Quick training (30 epochs for ablation)\n",
        "    for epoch in range(30):\n",
        "        train_loss, train_auc = train_epoch_enhanced(\n",
        "            model_ablation, train_loader_ablation, optimizer, criterion, device\n",
        "        )\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_auc = validate_enhanced(\n",
        "        model_ablation, test_loader_ablation, criterion, device\n",
        "    )\n",
        "\n",
        "    ablation_results[config['name']] = {\n",
        "        'test_auc': test_auc,\n",
        "        'description': config['description'],\n",
        "        'improvement': (test_auc - 0.7320) / 0.7320 * 100  # vs baseline\n",
        "    }\n",
        "\n",
        "    print(f\"Test AUC: {test_auc:.4f} (vs baseline: {ablation_results[config['name']]['improvement']:+.2f}%)\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ABLATION STUDY SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Configuration':<30} {'AUC':<8} {'vs Baseline':<12}\")\n",
        "print(\"-\"*50)\n",
        "for name, results in ablation_results.items():\n",
        "    print(f\"{results['description']:<30} {results['test_auc']:<8.4f} {results['improvement']:+.2f}%\")\n",
        "\n",
        "print(f\"\\n{'Full Model (All 3 features)':<30} {0.7393:<8.4f} {1.00:+.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4PmM1dFw1XPV",
        "outputId": "1b7eebf8-f6a1-4dc3-d37b-b9eae895cb3f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Feature Ablation Study\n",
            "============================================================\n",
            "\n",
            "Testing: Response Time Only\n",
            "Random seeds set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test AUC: 0.7347 (vs baseline: +0.37%)\n",
            "\n",
            "Testing: Hints Only\n",
            "Random seeds set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test AUC: 0.7386 (vs baseline: +0.91%)\n",
            "\n",
            "Testing: Attempts Only\n",
            "Random seeds set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test AUC: 0.7351 (vs baseline: +0.42%)\n",
            "\n",
            "Testing: Hints + Attempts (No RT)\n",
            "Random seeds set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test AUC: 0.7373 (vs baseline: +0.73%)\n",
            "\n",
            "Testing: RT + Attempts (No Hints)\n",
            "Random seeds set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test AUC: 0.7338 (vs baseline: +0.25%)\n",
            "\n",
            "Testing: RT + Hints (No Attempts)\n",
            "Random seeds set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test AUC: 0.7374 (vs baseline: +0.73%)\n",
            "\n",
            "============================================================\n",
            "ABLATION STUDY SUMMARY\n",
            "============================================================\n",
            "Configuration                  AUC      vs Baseline \n",
            "--------------------------------------------------\n",
            "Response Time Only             0.7347   +0.37%\n",
            "Hints Only                     0.7386   +0.91%\n",
            "Attempts Only                  0.7351   +0.42%\n",
            "Hints + Attempts (No RT)       0.7373   +0.73%\n",
            "RT + Attempts (No Hints)       0.7338   +0.25%\n",
            "RT + Hints (No Attempts)       0.7374   +0.73%\n",
            "\n",
            "Full Model (All 3 features)    0.7393   +1.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 23: Statistical Significance Test. Statistical Validation."
      ],
      "metadata": {
        "id": "H7AsYvWF1wiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 23: Statistical Significance Test - COMPLETE IMPLEMENTATION\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "def quick_train_baseline(seed, num_epochs=30):\n",
        "    \"\"\"Quick training for statistical test - fewer epochs for speed\"\"\"\n",
        "    set_seeds(seed)\n",
        "\n",
        "    # Initialize baseline model\n",
        "    model_baseline = SAKT(\n",
        "        num_skills=num_skills,\n",
        "        embed_dim=100,\n",
        "        num_heads=5,\n",
        "        dropout=0.2\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model_baseline.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    criterion = nn.BCELoss(reduction='none')\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_auc = train_epoch(\n",
        "            model_baseline, train_loader, optimizer, criterion, device\n",
        "        )\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_auc = validate_epoch(model_baseline, test_loader, criterion, device)\n",
        "    return test_auc\n",
        "\n",
        "def quick_train_enhanced(seed, num_epochs=20):\n",
        "    \"\"\"Quick training for enhanced model - fewer epochs for speed\"\"\"\n",
        "    set_seeds(seed)\n",
        "\n",
        "    # Initialize enhanced model\n",
        "    model_enhanced = BehavioralAwareSAKT(\n",
        "        num_skills=num_skills,\n",
        "        embed_dim=100,\n",
        "        num_heads=5,\n",
        "        dropout=0.2,\n",
        "        num_features=3\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model_enhanced.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    criterion = nn.BCELoss(reduction='none')\n",
        "\n",
        "    # Quick training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_auc = train_epoch_enhanced(\n",
        "            model_enhanced, train_loader_enh, optimizer, criterion, device\n",
        "        )\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_auc = validate_enhanced(model_enhanced, test_loader_enh, criterion, device)\n",
        "    return test_auc\n",
        "\n",
        "# Main statistical significance test\n",
        "print(\"Statistical Significance Testing\")\n",
        "print(\"=\"*60)\n",
        "print(\"Note: Using 20 epochs per run for speed (instead of 30)\")\n",
        "print()\n",
        "\n",
        "# Store results\n",
        "baseline_aucs = []\n",
        "enhanced_aucs = []\n",
        "seeds = [42, 123, 456, 789, 101]\n",
        "\n",
        "print(\"Running 5 random seeds for statistical test...\")\n",
        "\n",
        "for i, seed in enumerate(seeds):\n",
        "    print(f\"\\nRun {i+1}/5 with seed {seed}\")\n",
        "\n",
        "    # Train baseline model\n",
        "    print(\"  Training baseline model...\")\n",
        "    baseline_auc = quick_train_baseline(seed, num_epochs=20)\n",
        "    baseline_aucs.append(baseline_auc)\n",
        "    print(f\"  Baseline AUC: {baseline_auc:.4f}\")\n",
        "\n",
        "    # Train enhanced model\n",
        "    print(\"  Training enhanced model...\")\n",
        "    enhanced_auc = quick_train_enhanced(seed, num_epochs=20)\n",
        "    enhanced_aucs.append(enhanced_auc)\n",
        "    print(f\"  Enhanced AUC: {enhanced_auc:.4f}\")\n",
        "    print(f\"  Improvement: {enhanced_auc - baseline_auc:+.4f}\")\n",
        "\n",
        "# Convert to numpy arrays\n",
        "baseline_aucs = np.array(baseline_aucs)\n",
        "enhanced_aucs = np.array(enhanced_aucs)\n",
        "\n",
        "# Statistical analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STATISTICAL ANALYSIS RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Basic statistics\n",
        "print(f\"Baseline AUC - Mean: {baseline_aucs.mean():.4f}, Std: {baseline_aucs.std():.4f}\")\n",
        "print(f\"Enhanced AUC - Mean: {enhanced_aucs.mean():.4f}, Std: {enhanced_aucs.std():.4f}\")\n",
        "\n",
        "# Improvements for each run\n",
        "improvements = enhanced_aucs - baseline_aucs\n",
        "print(f\"Improvements - Mean: {improvements.mean():.4f}, Std: {improvements.std():.4f}\")\n",
        "print(f\"Individual improvements: {[f'{imp:.4f}' for imp in improvements]}\")\n",
        "\n",
        "# Paired t-test\n",
        "t_stat, p_value = stats.ttest_rel(enhanced_aucs, baseline_aucs)\n",
        "print(f\"\\nPaired t-test results:\")\n",
        "print(f\"t-statistic: {t_stat:.4f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "print(f\"Significant at Î±=0.05: {'Yes' if p_value < 0.05 else 'No'}\")\n",
        "print(f\"Significant at Î±=0.01: {'Yes' if p_value < 0.01 else 'No'}\")\n",
        "\n",
        "# Effect size (Cohen's d for paired samples)\n",
        "effect_size = improvements.mean() / improvements.std()\n",
        "print(f\"\\nEffect size (Cohen's d): {effect_size:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if effect_size > 0.8:\n",
        "    effect_interpretation = \"Large effect\"\n",
        "elif effect_size > 0.5:\n",
        "    effect_interpretation = \"Medium effect\"\n",
        "elif effect_size > 0.2:\n",
        "    effect_interpretation = \"Small effect\"\n",
        "else:\n",
        "    effect_interpretation = \"Negligible effect\"\n",
        "\n",
        "print(f\"Effect interpretation: {effect_interpretation}\")\n",
        "\n",
        "# 95% Confidence interval for the mean improvement\n",
        "from scipy.stats import t\n",
        "n = len(improvements)\n",
        "confidence_level = 0.95\n",
        "alpha = 1 - confidence_level\n",
        "dof = n - 1\n",
        "t_critical = t.ppf(1 - alpha/2, dof)\n",
        "margin_error = t_critical * (improvements.std() / np.sqrt(n))\n",
        "ci_lower = improvements.mean() - margin_error\n",
        "ci_upper = improvements.mean() + margin_error\n",
        "\n",
        "print(f\"\\n95% Confidence Interval for improvement:\")\n",
        "print(f\"[{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
        "\n",
        "# Summary for thesis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY FOR THESIS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"â€¢ BA-SAKT shows consistent improvement over baseline SAKT\")\n",
        "print(f\"â€¢ Mean improvement: {improvements.mean():.4f} AUC points\")\n",
        "print(f\"â€¢ Statistical significance: p = {p_value:.4f}\")\n",
        "print(f\"â€¢ Effect size: {effect_size:.4f} ({effect_interpretation.lower()})\")\n",
        "print(f\"â€¢ 95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(f\"â€¢ Result: Statistically significant improvement (p < 0.05)\")\n",
        "else:\n",
        "    print(f\"â€¢ Result: Improvement not statistically significant (p â‰¥ 0.05)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7m7htPxN1tbu",
        "outputId": "59cae1ab-f6d3-4da5-9e61-6a48b21449c2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistical Significance Testing\n",
            "============================================================\n",
            "Note: Using 20 epochs per run for speed (instead of 30)\n",
            "\n",
            "Running 5 random seeds for statistical test...\n",
            "\n",
            "Run 1/5 with seed 42\n",
            "  Training baseline model...\n",
            "Random seeds set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Baseline AUC: 0.7318\n",
            "  Training enhanced model...\n",
            "Random seeds set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Enhanced AUC: 0.7378\n",
            "  Improvement: +0.0060\n",
            "\n",
            "Run 2/5 with seed 123\n",
            "  Training baseline model...\n",
            "Random seeds set to 123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Baseline AUC: 0.7321\n",
            "  Training enhanced model...\n",
            "Random seeds set to 123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Enhanced AUC: 0.7380\n",
            "  Improvement: +0.0059\n",
            "\n",
            "Run 3/5 with seed 456\n",
            "  Training baseline model...\n",
            "Random seeds set to 456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Baseline AUC: 0.7321\n",
            "  Training enhanced model...\n",
            "Random seeds set to 456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Enhanced AUC: 0.7385\n",
            "  Improvement: +0.0064\n",
            "\n",
            "Run 4/5 with seed 789\n",
            "  Training baseline model...\n",
            "Random seeds set to 789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Baseline AUC: 0.7325\n",
            "  Training enhanced model...\n",
            "Random seeds set to 789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Enhanced AUC: 0.7381\n",
            "  Improvement: +0.0056\n",
            "\n",
            "Run 5/5 with seed 101\n",
            "  Training baseline model...\n",
            "Random seeds set to 101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Baseline AUC: 0.7300\n",
            "  Training enhanced model...\n",
            "Random seeds set to 101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Enhanced AUC: 0.7376\n",
            "  Improvement: +0.0076\n",
            "\n",
            "============================================================\n",
            "STATISTICAL ANALYSIS RESULTS\n",
            "============================================================\n",
            "Baseline AUC - Mean: 0.7317, Std: 0.0009\n",
            "Enhanced AUC - Mean: 0.7380, Std: 0.0003\n",
            "Improvements - Mean: 0.0063, Std: 0.0007\n",
            "Individual improvements: ['0.0060', '0.0059', '0.0064', '0.0056', '0.0076']\n",
            "\n",
            "Paired t-test results:\n",
            "t-statistic: 17.9763\n",
            "p-value: 0.0001\n",
            "Significant at Î±=0.05: Yes\n",
            "Significant at Î±=0.01: Yes\n",
            "\n",
            "Effect size (Cohen's d): 8.9882\n",
            "Effect interpretation: Large effect\n",
            "\n",
            "95% Confidence Interval for improvement:\n",
            "[0.0054, 0.0072]\n",
            "\n",
            "============================================================\n",
            "SUMMARY FOR THESIS\n",
            "============================================================\n",
            "â€¢ BA-SAKT shows consistent improvement over baseline SAKT\n",
            "â€¢ Mean improvement: 0.0063 AUC points\n",
            "â€¢ Statistical significance: p = 0.0001\n",
            "â€¢ Effect size: 8.9882 (large effect)\n",
            "â€¢ 95% CI: [0.0054, 0.0072]\n",
            "â€¢ Result: Statistically significant improvement (p < 0.05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 24: Final Results Visualization"
      ],
      "metadata": {
        "id": "O2VNLKhb2KEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 24: Final Results Visualization\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create summary plot\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Model comparison\n",
        "models = ['Baseline SAKT', 'BA-SAKT']\n",
        "aucs = [0.7320, 0.7393]\n",
        "ax1.bar(models, aucs, color=['blue', 'green'])\n",
        "ax1.set_ylabel('Test AUC')\n",
        "ax1.set_title('Model Performance Comparison')\n",
        "ax1.set_ylim(0.73, 0.74)\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(aucs):\n",
        "    ax1.text(i, v + 0.0005, f'{v:.4f}', ha='center')\n",
        "\n",
        "# Feature importance (from ablation)\n",
        "# Plot feature contributions\n",
        "features = ['Response Time', 'Hints', 'Attempts']\n",
        "contributions = [\n",
        "    ablation_results['response_time_only']['improvement'],\n",
        "    ablation_results['hints_only']['improvement'],\n",
        "    ablation_results['attempts_only']['improvement']\n",
        "]\n",
        "\n",
        "ax2.bar(features, contributions, color=['orange', 'purple', 'brown'])\n",
        "ax2.set_ylabel('Improvement over Baseline (%)')\n",
        "ax2.set_title('Individual Feature Contributions')\n",
        "ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('da_sakt_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Results saved to da_sakt_results.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "e0wHOrgP2Gei",
        "outputId": "d7fc38ce-1b7f-499f-88b2-94df91bc7936"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to da_sakt_results.png\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyP5BMFuNHi28OOc+OzUn7lt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}